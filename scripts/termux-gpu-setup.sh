#!/data/data/com.termux/files/usr/bin/bash
# Pocket LLM Termux GPU Setup Script
# Configures Ollama with GPU acceleration for Android devices

set -e

echo "==================================================="
echo "   Pocket LLM - Termux GPU Acceleration Setup"
echo "==================================================="
echo ""

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to detect device chipset
detect_chipset() {
    local chipset=$(getprop ro.board.platform)
    local gpu_info=$(dumpsys SurfaceFlinger | grep "GLES" | head -n 1)
    
    echo -e "${BLUE}Detecting device hardware...${NC}"
    echo "Platform: $chipset"
    echo "GPU Info: $gpu_info"
    
    if [[ "$chipset" == *"sm8"* ]] || [[ "$gpu_info" == *"Adreno"* ]]; then
        echo -e "${GREEN}âœ“ Snapdragon detected (Adreno GPU)${NC}"
        return 0
    elif [[ "$chipset" == *"exynos"* ]] || [[ "$gpu_info" == *"Mali"* ]] || [[ "$gpu_info" == *"Xclipse"* ]]; then
        echo -e "${GREEN}âœ“ Exynos detected (Mali/Xclipse GPU)${NC}"
        return 1
    else
        echo -e "${YELLOW}âš  Unknown chipset. Defaulting to CPU-only mode${NC}"
        return 2
    fi
}

# Function to install dependencies
install_dependencies() {
    echo -e "\n${BLUE}Installing required packages...${NC}"
    
    pkg update -y
    pkg upgrade -y
    
    # Core dependencies
    pkg install -y git cmake golang python numpy
    
    # Build tools
    pkg install -y clang make pkg-config
    
    # GPU libraries
    detect_chipset
    local chipset_type=$?
    
    if [ $chipset_type -eq 0 ]; then
        # Snapdragon/Adreno - OpenCL support
        pkg install -y opencl-headers opencl-clhpp opencl-vendor-driver || true
    elif [ $chipset_type -eq 1 ]; then
        # Exynos/Mali - Vulkan support
        pkg install -y vulkan-headers vulkan-loader-android || true
    else
        # CPU-only - install basic optimization libraries
        pkg install -y openblas || true
    fi
    
    echo -e "${GREEN}âœ“ Dependencies installed${NC}"
}

# Function to compile llama.cpp with GPU support
compile_llama_cpp() {
    echo -e "\n${BLUE}Compiling llama.cpp with GPU acceleration...${NC}"
    
    # Clone llama.cpp if not exists
    if [ ! -d "$HOME/llama.cpp" ]; then
        git clone https://github.com/ggerganov/llama.cpp.git $HOME/llama.cpp
    fi
    
    cd $HOME/llama.cpp
    git pull
    
    # Detect and set compilation flags
    detect_chipset
    local chipset_type=$?
    
    if [ $chipset_type -eq 0 ]; then
        # Snapdragon with OpenCL
        echo -e "${YELLOW}Compiling for Snapdragon (OpenCL)...${NC}"
        make clean
        make LLAMA_CLBLAST=1 \
             LLAMA_ACCELERATE=1 \
             LLAMA_OPENBLAS=1 \
             -j$(nproc)
    elif [ $chipset_type -eq 1 ]; then
        # Exynos with Vulkan
        echo -e "${YELLOW}Compiling for Exynos (Vulkan)...${NC}"
        make clean
        make LLAMA_VULKAN=1 \
             LLAMA_ACCELERATE=1 \
             LLAMA_OPENBLAS=1 \
             -j$(nproc)
    else
        # CPU-only fallback
        echo -e "${YELLOW}Compiling CPU-optimized version...${NC}"
        make clean
        make LLAMA_OPENBLAS=1 \
             LLAMA_ACCELERATE=1 \
             -j$(nproc)
    fi
    
    echo -e "${GREEN}âœ“ llama.cpp compiled successfully${NC}"
}

# Function to configure Ollama for GPU
configure_ollama() {
    echo -e "\n${BLUE}Configuring Ollama for GPU acceleration...${NC}"
    
    # Create Ollama config directory
    mkdir -p $HOME/.ollama
    
    # Detect optimal settings
    local gpu_layers=0
    local threads=$(nproc)
    
    detect_chipset
    local chipset_type=$?
    
    if [ $chipset_type -eq 0 ]; then
        # Snapdragon optimal settings
        gpu_layers=24  # 16-24 layers for Snapdragon
        echo -e "${GREEN}Snapdragon configuration:${NC}"
        echo "  GPU Layers: $gpu_layers"
        echo "  Threads: $threads"
    elif [ $chipset_type -eq 1 ]; then
        # Exynos optimal settings
        gpu_layers=16  # 8-16 layers for Exynos
        echo -e "${GREEN}Exynos configuration:${NC}"
        echo "  GPU Layers: $gpu_layers"
        echo "  Threads: $threads"
    else
        echo -e "${YELLOW}CPU-only configuration${NC}"
        gpu_layers=0
    fi
    
    # Create Ollama environment file
    cat > $HOME/.ollama/environment << EOF
# Ollama GPU Configuration
# Generated by Pocket LLM GPU Setup

# GPU Settings
OLLAMA_NUM_GPU=1
OLLAMA_GPU_LAYERS=$gpu_layers
OLLAMA_MAIN_GPU=0
OLLAMA_LOW_VRAM=false

# CPU Settings
OLLAMA_NUM_THREAD=$threads
OLLAMA_NUM_CPU=$threads

# Memory Settings
OLLAMA_MAX_LOADED_MODELS=1
OLLAMA_MEMORY_LIMIT=4GB

# Performance Settings
OLLAMA_BATCH_SIZE=512
OLLAMA_CONTEXT_SIZE=4096

# Model Loading Timeout
OLLAMA_LOAD_TIMEOUT=120
EOF
    
    echo -e "${GREEN}âœ“ Ollama configured for GPU acceleration${NC}"
}

# Function to create start script
create_start_script() {
    echo -e "\n${BLUE}Creating optimized start script...${NC}"
    
    cat > $HOME/start-ollama-gpu.sh << 'EOF'
#!/data/data/com.termux/files/usr/bin/bash

# Load GPU configuration
if [ -f $HOME/.ollama/environment ]; then
    source $HOME/.ollama/environment
fi

# Export environment variables
export $(grep -v '^#' $HOME/.ollama/environment | xargs)

# Start Ollama with GPU support
echo "Starting Ollama with GPU acceleration..."
ollama serve
EOF
    
    chmod +x $HOME/start-ollama-gpu.sh
    
    echo -e "${GREEN}âœ“ Start script created at ~/start-ollama-gpu.sh${NC}"
}

# Function to test GPU acceleration
test_gpu() {
    echo -e "\n${BLUE}Testing GPU acceleration...${NC}"
    
    # Start Ollama in background
    $HOME/start-ollama-gpu.sh &
    local ollama_pid=$!
    
    # Wait for Ollama to start
    sleep 5
    
    # Test with a small model
    echo "Loading test model (qwen2:0.5b)..."
    ollama pull qwen2:0.5b
    
    # Run a simple inference test
    echo "Running inference test..."
    time ollama run qwen2:0.5b "Hello, how are you?" --verbose
    
    # Kill Ollama
    kill $ollama_pid
    
    echo -e "${GREEN}âœ“ GPU test completed${NC}"
}

# Function to display optimization tips
show_tips() {
    echo -e "\n${BLUE}=== Optimization Tips ===${NC}"
    echo ""
    
    detect_chipset
    local chipset_type=$?
    
    if [ $chipset_type -eq 0 ]; then
        echo "ðŸ“± Samsung S24+ Snapdragon Tips:"
        echo "  â€¢ Use Phi-3-mini (3.8B) Q4_K_M for best balance"
        echo "  â€¢ Set GPU layers to 24 for optimal speed"
        echo "  â€¢ Enable Low VRAM mode if experiencing crashes"
    elif [ $chipset_type -eq 1 ]; then
        echo "ðŸ“± Samsung S24+ Exynos Tips:"
        echo "  â€¢ Use Gemma-2b Q4_K_M for stability"
        echo "  â€¢ Set GPU layers to 12-16"
        echo "  â€¢ Reduce batch size if memory errors occur"
    else
        echo "ðŸ“± CPU-only Tips:"
        echo "  â€¢ Use smaller models (1-2B parameters)"
        echo "  â€¢ Reduce context window size"
        echo "  â€¢ Consider using cloud models instead"
    fi
    
    echo ""
    echo "ðŸš€ General Performance Tips:"
    echo "  â€¢ Close other apps to free memory"
    echo "  â€¢ Use quantized models (Q4_K_M or Q5_K_M)"
    echo "  â€¢ Adjust gpu_layers based on available RAM"
    echo "  â€¢ Monitor temperature - reduce layers if overheating"
    echo ""
    echo -e "${YELLOW}Edit ~/.ollama/environment to fine-tune settings${NC}"
}

# Main installation flow
main() {
    echo "This script will configure GPU acceleration for Ollama"
    echo "Optimized for Samsung S24+ and similar devices"
    echo ""
    read -p "Continue with installation? (y/n) " -n 1 -r
    echo ""
    
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Installation cancelled"
        exit 1
    fi
    
    install_dependencies
    compile_llama_cpp
    configure_ollama
    create_start_script
    
    echo ""
    echo -e "${GREEN}=== Installation Complete ===${NC}"
    echo ""
    echo "To start Ollama with GPU acceleration:"
    echo "  ./start-ollama-gpu.sh"
    echo ""
    echo "To test GPU performance:"
    read -p "Run GPU test now? (y/n) " -n 1 -r
    echo ""
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        test_gpu
    fi
    
    show_tips
    
    echo ""
    echo -e "${GREEN}âœ“ Setup complete! Happy inferencing! ðŸš€${NC}"
}

# Run main function
main